{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607e255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoodongseok/Desktop/rag_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3264661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœì •ì˜\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    docs: List[str]\n",
    "    summary: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa02ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive ë…¸ë“œ (ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ)\n",
    "def retrieve_docs(state: RAGState):\n",
    "    print(\"Retrieving relevant documents...\")\n",
    "    \n",
    "    loader = WebBaseLoader(\"https://ko.wikipedia.org/wiki/ëŒ€í•œë¯¼êµ­\") # loader ìƒì„±\n",
    "    docs = loader.load() # docsì— ë¬¸ì„œ ë¡œë“œ\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # splitter ì •ì˜\n",
    "    chunks = splitter.split_documents(docs) # docs ì²­í‚¹\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # ì„ë² ë”© ëª¨ë¸ ì •ì˜\n",
    "    vectordb = Chroma.from_documents(chunks, embedding=embeddings) # ì²­í‚¹ëœ ë¬¸ì„œë“¤ì„ ì„ë² ë”©ì‹œì¼œì„œ ë²¡í„°DBì— ì €ì¥\n",
    "    \n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\":3}) # ìœ ì‚¬í•œ í‚¤ì›Œë“œ 3ê°œ ê²€ìƒ‰\n",
    "    retrived_docs = retriever.invoke(state[\"question\"]) # ì§ˆë¬¸\n",
    "    \n",
    "    return {'docs': [d.page_content for d in retrived_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72731681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoner ë…¸ë“œ (ë¬¸ì„œ ìš”ì•½ ë° í•µì‹¬ ì¶”ë¡ )\n",
    "def reason_over_docs(state: RAGState):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì§ˆë¬¸ì— í•„ìš”í•œ í•µì‹¬ ë§¥ë½ ì •ì˜\"\"\"\n",
    "    print(\"Reasoning about retrieved docs...\")\n",
    "    \n",
    "    llm = ChatOllama(model=\"llama3:8b\", temperature=0)\n",
    "    context = \"\\n\\n\".join(state[\"docs\"])[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ë„ˆëŠ” ë¬¸ì„œ ìš”ì•½ ë° ë¶„ì„ ì „ë¬¸ê°€ì•¼.\n",
    "    ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì•¼ í•´.\n",
    "    ì•„ë˜ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•´ì¤˜.\n",
    "    \n",
    "    [ë¬¸ì„œ ë‚´ìš©]\n",
    "    {context}\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {state['question']} \n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return {\"summary\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d9c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator ë…¸ë“œ (ìµœì¢… ì‘ë‹µ ìƒì„±)\n",
    "def generate_final_answer(state: RAGState):\n",
    "    \"\"\"Reasonerê°€ ì •ë¦¬í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ë‹µë³€ ìƒì„±\"\"\"\n",
    "    print(\"Generating final answer...\")\n",
    "    \n",
    "    llm = ChatOllama(model=\"llama3:8b\", temperature=0.3)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ìš”ì•½ ë‚´ìš©ì´ì•¼.\n",
    "    ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.\n",
    "    \n",
    "    [ìš”ì•½ëœ ë‚´ìš©]\n",
    "    {state[\"summary\"]}\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {state[\"question\"]}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2bb433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langgraph êµ¬ì„±\n",
    "workflow = StateGraph(RAGState)\n",
    "workflow.add_node(\"retriever\", retrieve_docs)\n",
    "workflow.add_node(\"reasoner\", reason_over_docs)\n",
    "workflow.add_node(\"generator\", generate_final_answer)\n",
    "\n",
    "workflow.add_edge(START, \"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"reasoner\")\n",
    "workflow.add_edge(\"reasoner\", \"generator\")\n",
    "workflow.add_edge(\"generator\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bf569ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\n",
      "Retrieving relevant documents...\n",
      "Reasoning about retrieved docs...\n",
      "Generating final answer...\n",
      "\n",
      "âœ… ìµœì¢… ë‹µë³€:\n",
      "ğŸ˜Š\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤! ğŸ™ï¸\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    result = app.invoke({\"question\": question})\n",
    "    print(\"\\nâœ… ìµœì¢… ë‹µë³€:\")\n",
    "    print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636889df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
